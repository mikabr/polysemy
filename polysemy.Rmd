---
title: "Polysemy Analysis"
author: "Mika Braginsky and Dan Yurovsky"
date: "February 27, 2015"
output:
  html_document:
    highlight: tango
    theme: spacelab
---
  
```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE)
```

```{r libraries, cache=FALSE}
source("~/Documents/projects/Ranalysis/useful.R")
library(arm)
library(ggplot2)
library(dplyr)
library(tidyr)
library(magrittr)
library(RMySQL)
library(stringr)
extract <- tidyr::extract
rename <- dplyr::rename
select <- dplyr::select
filter <- dplyr::filter
summarise <- dplyr::summarise
```

```{r database, cache=FALSE}
wordbank <- src_mysql(dbname="wordbank")

#wordbank <- src_mysql(dbname="wordbank", host="54.149.39.46",
#                      user="wordbank", password="wordbank")

wordmapping.table <- tbl(wordbank, "common_wordmapping")
instruments.table <- tbl(wordbank, "common_instrumentsmap")
english.ws.table <- tbl(wordbank, "instruments_english_ws")
english.wg.table <- tbl(wordbank, "instruments_english_wg")
```

```{r item_data}
# get item info
mapping <- as.data.frame(wordmapping.table)

# get instrument info
instruments <- as.data.frame(instruments.table) %>%
  rename(instrument_id = id)

# join items and instruments together
items <- left_join(mapping, instruments) %>%
  mutate(language = factor(language, levels = c("Norwegian", "English", "Danish", "Spanish")))
```

```{r ws_data}
ws.items <- items %>% 
  filter(language == "English", form == "WS", type == "word") %>%
  select(item_id, item) %>%
  mutate(item_id = as.numeric(substr(item_id, 6, nchar(item_id))))
      
ws.columns <- colnames(english.ws.table)
ws.names <- ws.columns[2:length(ws.columns)]

ws.bykid <- as.data.frame(english.ws.table) %>%
  mutate(id = as.numeric(basetable_ptr_id)) %>%
  select(-basetable_ptr_id) %>%
  gather_("item_id", "value", ws.names, convert=TRUE) %>%
  mutate(item_id = as.numeric(substr(item_id, 6, nchar(item_id))))

ws.data <- left_join(ws.bykid, ws.items, by=c("item_id")) %>%
  select(-item_id)

ws.poly.data <- ws.data %>%
  filter(grepl("\\.",item)==TRUE)
ws.poly.data[is.na(ws.poly.data$value),]$value = ""
```

```{r ws_conditionals}
ws.all.pairs <- expand.grid(item = unique(ws.poly.data$item),
                         pair = unique(ws.poly.data$item))

ws.item.data <- left_join(ws.poly.data, ws.all.pairs, by = c("item")) %>%
  rename(item.value = value)

ws.pair.data <- ws.item.data %>%
  mutate(pair.tmp = item,
         item = pair,
         pair = pair.tmp) %>%
  select(-pair.tmp) %>%
  rename(pair.value = item.value) %>%
  arrange(id,item)

ws.all.data <- inner_join(ws.item.data, ws.pair.data)

ws.and.data <- ws.all.data %>%
  rowwise() %>%
  mutate(both = item.value == "produces" & pair.value == "produces")

ws.summary.data <- ws.and.data %>%
  group_by(item, pair) %>%
  summarise(prop.both = sum(both) / length(both))

ws.match <- ws.summary.data %>%
  filter(item == pair) %>%
  ungroup() %>%
  select(-item) %>%
  rename(prop.pair = prop.both)

ws.cond.data <- left_join(ws.summary.data, ws.match) %>%
  mutate(conditional = prop.both / prop.pair) %>%
  filter(item != pair) %>%
  separate(item, c("item.word", "item.category"), "\\.") %>%
  mutate(item = paste(item.word, " (", item.category, ")", sep="")) %>%
  separate(pair, c("pair.word", "pair.category"), "\\.") %>%
  mutate(pair = paste(pair.word, " (", pair.category, ")", sep="")) %>%
  mutate(same = factor(ifelse(item.word == pair.word,
                              "same word", "different word"))) %>%
  select(item, pair, same, conditional)

ws.means.data <- ws.cond.data %>%
  group_by(item) %>%
  summarise(mean = mean(conditional),
            ci.low = ci.low(conditional),
            ci.high = ci.high(conditional))

ws.cond.mean.data <- left_join(ws.cond.data, ws.means.data, by="item") %>%
  mutate(item = factor(item))
```

```{r wg_data}
wg.items <- items %>% 
  filter(language == "English", form == "WG", type == "word") %>%
  select(item_id, item) %>%
  mutate(item_id = as.numeric(substr(item_id, 6, nchar(item_id))))
      
wg.columns <- colnames(english.wg.table)
wg.names <- wg.columns[2:length(wg.columns)]

wg.bykid <- as.data.frame(english.wg.table) %>%
  mutate(id = as.numeric(basetable_ptr_id)) %>%
  select(-basetable_ptr_id) %>%
  gather_("item_id", "value", wg.names, convert=TRUE) %>%
  mutate(item_id = as.numeric(substr(item_id, 6, nchar(item_id))))

wg.data <- left_join(wg.bykid, wg.items, by=c("item_id")) %>%
  select(-item_id)

wg.poly.data <- wg.data %>%
  filter(grepl("\\.",item)==TRUE)
wg.poly.data[is.na(wg.poly.data$value),]$value = ""
```

```{r wg_conditionals}
wg.all.pairs <- expand.grid(item = unique(wg.poly.data$item),
                         pair = unique(wg.poly.data$item))

wg.item.data <- left_join(wg.poly.data, wg.all.pairs, by = c("item")) %>%
  rename(item.value = value)

wg.pair.data <- wg.item.data %>%
  mutate(pair.tmp = item,
         item = pair,
         pair = pair.tmp) %>%
  select(-pair.tmp) %>%
  rename(pair.value = item.value) %>%
  arrange(id,item)

wg.all.data <- inner_join(wg.item.data, wg.pair.data)

wg.and.data <- wg.all.data %>%
  rowwise() %>%
  mutate(both.produces = item.value == "produces" & pair.value == "produces",
         both.understands = (item.value == "produces" | item.value == "understands") &
           (pair.value == "produces" | pair.value == "understands"))

wg.summary.data <- wg.and.data %>%
  group_by(item, pair) %>%
  summarise(prop.both.produces = sum(both.produces) / length(both.produces),
            prop.both.understands = sum(both.understands) / length(both.understands))

wg.match <- wg.summary.data %>%
  filter(item == pair) %>%
  ungroup() %>%
  select(-item) %>%
  rename(prop.pair.produces = prop.both.produces,
         prop.pair.understands = prop.both.understands)

wg.cond.data <- left_join(wg.summary.data, wg.match) %>%
  mutate(conditional.produces = prop.both.produces / prop.pair.produces,
         conditional.understands = prop.both.understands / prop.pair.understands) %>%
  filter(item != pair) %>%
  separate(item, c("item.word", "item.category"), "\\.") %>%
  mutate(item = paste(item.word, " (", item.category, ")", sep="")) %>%
  separate(pair, c("pair.word", "pair.category"), "\\.") %>%
  mutate(pair = paste(pair.word, " (", pair.category, ")", sep="")) %>%
  mutate(same = factor(ifelse(item.word == pair.word,
                              "same word", "different word"))) %>%
  select(item, pair, same, conditional.produces, conditional.understands)

wg.means.data <- wg.cond.data %>%
  group_by(item) %>%
  summarise(mean.produces = mean(conditional.produces),
            cilow.produces = ci.low(conditional.produces),
            cihigh.produces = ci.high(conditional.produces),
            mean.understands = mean(conditional.understands),
            cilow.understands = ci.low(conditional.understands),
            cihigh.understands = ci.high(conditional.understands))

wg.cond.mean.data <- left_join(wg.cond.data, wg.means.data, by="item") %>%
  mutate(item = factor(item)) %>%
  gather(measure.quantity, value, conditional.produces, conditional.understands,
         mean.produces, cilow.produces, cihigh.produces,
         mean.understands, cilow.understands, cihigh.understands) %>%
  extract(measure.quantity, c("quantity","measure"),
          "([[:alnum:]]+)\\.([[:alnum:]]+)")

wg.prod <- wg.cond.mean.data %>%
  filter(measure == "produces") %>%
  spread(quantity, value)
wg.comp <- wg.cond.mean.data %>%
  filter(measure == "understands") %>%
  spread(quantity, value)
wg.prod.comp <- rbind(wg.prod, wg.comp)
```

This analysis uses data from [Wordbank](http://wordbank.stanford.edu/), an open database that aggregates administrations of the CDI across labs and languages. We take the `r nrow(ws.poly.data) / length(unique(ws.poly.data$item))` administrations of English Words & Sentences and the `r nrow(wg.poly.data) / length(unique(wg.poly.data$item))` administrations of English Words & Gestures, and examine the set of words that appear twice on the form in different semantic categories. These words vary in whether their meanings are polysemous (e.g. "chicken" in Animals and "chicken" in Food and Drink) or homonymous (e.g. "can" in Small Household Objects and "can" in Helping Verbs). There are `r length(unique(ws.poly.data$item))` such words on English WS and `r length(unique(wg.poly.data$item))` such words on English WG.

For each of these words, we compute the proportion of children that are reported to produce it. Then for each pair of these words (both matched in form and not matched in form), we compute the proportion of children that are reported to produce both of them. We then compute the conditional probability of producing word A on word B as the proportion producing both A and B divided by the proportion producing word B.

The plot below shows the Words & Sentences data, with each point being the conditional probability of producing the x-axis word on producing one of the other words. The large teal point is that probability for the form-matched pair, while the small red points are those probabilities for all the other, non-form matched words. The interval shows a bootstrapped 95% confidence interval on the mean of all the conditional probabilities.

```{r ws_plot, fig.width=10, fig.height=6}
#quartz(width=8, height=6)
ggplot(ws.cond.mean.data, aes(x=item, y=conditional, colour=same)) +
  geom_point(aes(size=same)) +
  scale_size_discrete(range = c(1,3)) +
  geom_errorbar(aes(x=item, ymax=mean+ci.high, ymin=mean-ci.low, width=0.3)) +
  geom_vline(aes(xintercept = seq(2.5,length(levels(item))+0.5,2)),
             linetype = "dashed", colour="gray") +
  xlab("") + 
  ylab("Conditional Probabilities") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5),
        legend.position = "none")
```

The plot below shows the same analysis on Words and Gestures data, with proportions computed over both measures on the form ("understands" and "produces").

```{r wg_plot_prod, fig.width=10, fig.height=8}
#quartz(width=8, height=6)
ggplot(wg.prod.comp, aes(x=item, y=conditional, colour=same)) +
  facet_grid(measure ~ .) +
  geom_point(aes(size=same)) +
  scale_size_discrete(range = c(1,3)) +
  geom_errorbar(aes(x=item, ymax=mean+cihigh,
                    ymin=mean-cilow, width=0.3)) +
  geom_vline(aes(xintercept = seq(2.5,length(levels(item))+0.5,2)),
             linetype = "dashed", colour="gray") +
  xlab("") + 
  ylab("Conditional Probabilities") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5),
        legend.position = "none")
```